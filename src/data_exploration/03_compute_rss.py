# -*- coding: utf-8 -*-
"""03_compute_rss.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a57aEa80HcBivp8NKR2mbYhzbObWqu7w
"""

# Commented out IPython magic to ensure Python compatibility.
# mount drive & navigate
from google.colab import drive
drive.mount('/content/drive')
!git clone https://github.com/urverse/Visualizing-the-T.git
# %cd Visualizing-the-T

# install libraries
!pip install pyspark -q

# imports
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
import seaborn as sns
import matplotlib.pyplot as plt

print("‚úÖ Setup complete")

# load indicators from Eric's output
travel_indicators = pd.read_parquet("data/indicators/travel_reliability_indicators.parquet")
restriction_indicators = pd.read_parquet("data/indicators/restriction_indicators.parquet")
ridership_weights = pd.read_parquet("data/indicators/ridership_weights.parquet")

print("=== INDICATORS LOADED ===")
print(f"Travel reliability: {len(travel_indicators):,} segments")
print(f"Restrictions: {len(restriction_indicators)} lines")
print(f"Ridership weights: {len(ridership_weights)} line-periods")

# preview
print("\n=== TRAVEL INDICATORS SAMPLE ===")
print(travel_indicators.head())

# aggregate travel indicators by route
travel_by_route = travel_indicators.groupby('route_id').agg({
    'median_travel_time': 'mean',
    'travel_time_volatility': 'mean',
    'buffer_time_index': 'mean',
    'planning_time_index': 'mean',
    'on_time_performance': 'mean',
    'n_observations': 'sum'
}).reset_index()

print("=== TRAVEL METRICS BY ROUTE ===")
print(travel_by_route)

# aggregate ridership by route
ridership_by_route = ridership_weights.groupby('route_id').agg({
    'avg_daily_ridership': 'sum',
    'exposure_weight': 'sum'
}).reset_index()

print("\n=== RIDERSHIP BY ROUTE ===")
print(ridership_by_route)

# clean restriction line names (remove " Line" suffix)
restriction_indicators['route_id'] = restriction_indicators['line'].str.replace(' Line', '')

print("\n=== RESTRICTION METRICS ===")
print(restriction_indicators[['route_id', 'n_restrictions', 'avg_speed_mph',
                              'total_miles_restricted', 'severity_index']])

# join all indicators by route
rss_data = travel_by_route.merge(ridership_by_route, on='route_id', how='left')
rss_data = rss_data.merge(
    restriction_indicators[['route_id', 'n_restrictions', 'total_miles_restricted', 'severity_index']],
    on='route_id',
    how='left'
)

print("=== COMBINED INDICATORS ===")
print(rss_data)

# select key indicators for RSS
indicators_for_rss = [
    'median_travel_time',
    'travel_time_volatility',
    'buffer_time_index',
    'on_time_performance',
    'total_miles_restricted',
    'severity_index'
]

# normalize using z-scores
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

rss_data_normalized = rss_data.copy()
rss_data_normalized[indicators_for_rss] = scaler.fit_transform(rss_data[indicators_for_rss])

print("\n=== NORMALIZED INDICATORS (Z-SCORES) ===")
print(rss_data_normalized[['route_id'] + indicators_for_rss])

# invert indicators where lower is better
rss_data_normalized['travel_time_score'] = -rss_data_normalized['median_travel_time']
rss_data_normalized['volatility_score'] = -rss_data_normalized['travel_time_volatility']
rss_data_normalized['buffer_score'] = -rss_data_normalized['buffer_time_index']
rss_data_normalized['otp_score'] = rss_data_normalized['on_time_performance']
rss_data_normalized['restriction_score'] = -rss_data_normalized['total_miles_restricted']

# compute RSS with equal weights
rss_data_normalized['RSS_equal'] = (
    0.2 * rss_data_normalized['travel_time_score'] +
    0.2 * rss_data_normalized['volatility_score'] +
    0.2 * rss_data_normalized['buffer_score'] +
    0.2 * rss_data_normalized['otp_score'] +
    0.2 * rss_data_normalized['restriction_score']
)

# scale to 60-100
rss_min = rss_data_normalized['RSS_equal'].min()
rss_max = rss_data_normalized['RSS_equal'].max()
rss_data_normalized['RSS_equal_scaled'] = 60 + 40 * (
    rss_data_normalized['RSS_equal'] - rss_min
) / (rss_max - rss_min)

print("=== RSS WITH EQUAL WEIGHTS (60-100 SCALE) ===")
print(rss_data_normalized[['route_id', 'RSS_equal_scaled']].sort_values('RSS_equal_scaled', ascending=False))

# load survey data
survey = pd.read_csv("data/processed/passenger_survey_sample.csv")

print("=== SURVEY DATA SAMPLE ===")
print(survey.head())

# extract satisfaction scores by service mode/line
# survey has satisfaction percentages by reporting group
satisfaction_data = survey[
    (survey['measure_group'] == 'Trip Purpose and Frequency') &
    (survey['measure'] == 'Trip Purpose')
].copy()

print("\n=== SURVEY STRUCTURE ===")
print(survey['service_mode'].unique())
print("\nMeasure groups:")
print(survey['measure_group'].unique())

# extract rapid transit lines from service_mode
survey['line_extracted'] = survey['service_mode'].str.extract(r'- (Red|Blue|Orange|Green) Line')

# find satisfaction-related measures
print("=== AVAILABLE MEASURES ===")
print(survey['measure'].unique())

# check for satisfaction or rating measures
satisfaction_measures = survey[survey['measure'].str.contains('Satisfaction|Rating|Quality', case=False, na=False)]
print("\n=== SATISFACTION MEASURES ===")
print(satisfaction_measures[['service_mode', 'measure', 'category', 'weighted_percent']].head(10))

# if no direct satisfaction, we'll use frequency as proxy (higher frequency = higher satisfaction)
# or check what measures relate to service quality

# since survey lacks satisfaction scores, we'll use data-driven weights
# based on indicator importance (from literature: OTP and reliability matter most)

# literature-based weights (transit research shows these priorities)
weights_literature = {
    'travel_time_score': 0.15,      # moderate importance
    'volatility_score': 0.25,        # high - riders hate unpredictability
    'buffer_score': 0.25,            # high - planning reliability
    'otp_score': 0.25,               # high - on-time is critical
    'restriction_score': 0.10        # low - indirect impact
}

rss_data_normalized['RSS_literature'] = (
    weights_literature['travel_time_score'] * rss_data_normalized['travel_time_score'] +
    weights_literature['volatility_score'] * rss_data_normalized['volatility_score'] +
    weights_literature['buffer_score'] * rss_data_normalized['buffer_score'] +
    weights_literature['otp_score'] * rss_data_normalized['otp_score'] +
    weights_literature['restriction_score'] * rss_data_normalized['restriction_score']
)

# scale to 60-100
rss_min = rss_data_normalized['RSS_literature'].min()
rss_max = rss_data_normalized['RSS_literature'].max()
rss_data_normalized['RSS_literature_scaled'] = 60 + 40 * (
    rss_data_normalized['RSS_literature'] - rss_min
) / (rss_max - rss_min)

print("=== RSS COMPARISON ===")
print(rss_data_normalized[['route_id', 'RSS_equal_scaled', 'RSS_literature_scaled']].sort_values('RSS_literature_scaled', ascending=False))

import matplotlib.pyplot as plt
import seaborn as sns

# prepare data for plotting
rss_comparison = rss_data_normalized[['route_id', 'RSS_equal_scaled', 'RSS_literature_scaled']].melt(
    id_vars='route_id',
    var_name='Method',
    value_name='RSS'
)
rss_comparison['Method'] = rss_comparison['Method'].map({
    'RSS_equal_scaled': 'Equal Weights',
    'RSS_literature_scaled': 'Literature-Based Weights'
})

# MBTA line colors
color_map = {'Orange': '#ED8B00', 'Blue': '#003DA5', 'Red': '#DA291C'}

# create visualizations
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. RSS comparison by method
sns.barplot(data=rss_comparison, x='route_id', y='RSS', hue='Method', ax=axes[0,0], palette='Set2')
axes[0,0].set_title('RSS by Weighting Method', fontsize=14, fontweight='bold')
axes[0,0].set_ylabel('RSS (60-100 scale)')
axes[0,0].set_xlabel('Route')
axes[0,0].set_ylim(55, 105)
axes[0,0].legend(title='Method')

# 2. Literature-based RSS with line colors
rss_lit = rss_data_normalized.sort_values('RSS_literature_scaled', ascending=False)
colors = [color_map[route] for route in rss_lit['route_id']]
bars = axes[0,1].bar(rss_lit['route_id'], rss_lit['RSS_literature_scaled'], color=colors)
axes[0,1].set_title('RSS - Literature-Based Weights (Final)', fontsize=14, fontweight='bold')
axes[0,1].set_ylabel('RSS (60-100 scale)')
axes[0,1].set_xlabel('Route')
axes[0,1].set_ylim(55, 105)
for i, v in enumerate(rss_lit['RSS_literature_scaled']):
    axes[0,1].text(i, v+1.5, f'{v:.1f}', ha='center', fontweight='bold')

# 3. Component contribution heatmap
components = rss_data_normalized[['route_id', 'travel_time_score', 'volatility_score',
                                   'buffer_score', 'otp_score', 'restriction_score']].set_index('route_id')
sns.heatmap(components.T, annot=True, fmt='.2f', cmap='RdYlGn', center=0, ax=axes[1,0], cbar_kws={'label': 'Z-score'})
axes[1,0].set_title('Component Scores by Route', fontsize=14, fontweight='bold')
axes[1,0].set_ylabel('Component')
axes[1,0].set_xlabel('Route')

# 4. Key metrics comparison
metrics_compare = rss_data_normalized[['route_id', 'on_time_performance', 'travel_time_volatility',
                                        'total_miles_restricted']].set_index('route_id')
metrics_compare.plot(kind='bar', ax=axes[1,1], width=0.8)
axes[1,1].set_title('Key Performance Metrics (Raw)', fontsize=14, fontweight='bold')
axes[1,1].set_ylabel('Value')
axes[1,1].set_xlabel('Route')
axes[1,1].legend(['OTP', 'Volatility', 'Restricted Miles'])
axes[1,1].tick_params(axis='x', rotation=0)

plt.tight_layout()
plt.show()

print("‚úÖ Visualizations complete")

# save RSS results
rss_data_normalized.to_csv('data/processed/rss_final_results.csv', index=False)

# save weights for documentation
weights_df = pd.DataFrame({
    'Component': ['travel_time', 'volatility', 'buffer_time', 'on_time_performance', 'restrictions'],
    'Equal_Weight': [0.2, 0.2, 0.2, 0.2, 0.2],
    'Literature_Weight': [0.15, 0.25, 0.25, 0.25, 0.10],
    'Rationale': [
        'Moderate - absolute travel time matters less than reliability',
        'High - unpredictability frustrates riders most',
        'High - riders need to plan around delays',
        'High - meeting expectations is critical',
        'Low - indirect impact on rider experience'
    ]
})
weights_df.to_csv('data/processed/rss_weights.csv', index=False)

print("="*70)
print("RSS CALCULATION COMPLETE - WEEK 2 DELIVERABLE")
print("="*70)

print("\nüìä FINAL RSS SCORES (Literature-Based Weights):")
final_scores = rss_data_normalized[['route_id', 'RSS_literature_scaled']].sort_values('RSS_literature_scaled', ascending=False)
for _, row in final_scores.iterrows():
    print(f"  {row['route_id']:>6}: {row['RSS_literature_scaled']:>6.1f}")

print("\nüîë KEY INSIGHTS:")
print("  ‚Ä¢ Orange Line: Best overall (100.0)")
print("    - Excellent OTP (1.06 z-score)")
print("    - Low volatility (0.30 z-score)")
print("  ‚Ä¢ Red Line: Middle (68.0)")
print("    - Best volatility (1.05 z-score)")
print("    - Worst OTP (-1.34 z-score)")
print("  ‚Ä¢ Blue Line: Lowest (60.0)")
print("    - Worst volatility (-1.35 z-score)")
print("    - Worst buffer time (-1.39 z-score)")

print("\n‚öôÔ∏è METHODOLOGY:")
print("  ‚Ä¢ Data: 1,850 route segments, 36K trips")
print("  ‚Ä¢ Indicators: Travel time, volatility, buffer, OTP, restrictions")
print("  ‚Ä¢ Normalization: Z-scores")
print("  ‚Ä¢ Weights: Literature-based (reliability prioritized)")
print("  ‚Ä¢ Scale: 60-100")

print("\n‚úÖ DELIVERABLES:")
print("  ‚Ä¢ rss_final_results.csv - all scores and components")
print("  ‚Ä¢ rss_weights.csv - weight justifications")
print("  ‚Ä¢ Visualizations - 4 charts")

print("\nüìÅ NEXT STEPS (Week 3):")
print("  1. Time-period granularity (peak vs off-peak)")
print("  2. Station-level RSS breakdowns")
print("  3. Equity analysis by demographics")
print("  4. Interactive dashboard")
print("  5. Hypothesis testing (route comparisons)")

print("="*70)
