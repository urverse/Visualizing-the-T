# -*- coding: utf-8 -*-
"""01_data_exploration.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QTGuWkvpzPFId76qXWJV50-9tZtPX1cQ
"""

# install pyspark
!pip install pyspark -q

# import libraries
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# mount drive
from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# clone your repo (first time only)
!git clone https://github.com/urverse/Visualizing-the-T.git
# %cd Visualizing-the-T

# if already cloned, just navigate
# %cd /content/Visualizing-the-T
# !git pull

# set git credentials
!git config --global user.email "dhanrithi22@gmail.com"
!git config --global user.name "Dhanrithii D"

# create spark session
spark = SparkSession.builder \
    .appName("MBTA_Exploration") \
    .config("spark.driver.memory", "4g") \
    .getOrCreate()

# load all datasets
survey_df = spark.read.csv("data/processed/passenger_survey_sample.csv", header=True, inferSchema=True)
ridership_df = spark.read.csv("data/processed/ridership_sample.csv", header=True, inferSchema=True)
restrictions_df = spark.read.csv("data/processed/speed_restrictions_sample.csv", header=True, inferSchema=True)
travel_times_df = spark.read.csv("data/processed/travel_times_sample.csv", header=True, inferSchema=True)

print("‚úÖ Data loaded successfully")

# check schema
print("=== PASSENGER SURVEY SCHEMA ===")
survey_df.printSchema()

# sample rows
print("\n=== SAMPLE ROWS ===")
survey_df.show(5, truncate=False)

# row count
print(f"\nTotal rows: {survey_df.count():,}")

# check ridership schema
print("=== RIDERSHIP SCHEMA ===")
ridership_df.printSchema()

# sample rows
print("\n=== SAMPLE ROWS ===")
ridership_df.show(5, truncate=False)

# row count
print(f"\nTotal rows: {ridership_df.count():,}")

# check travel times schema
print("=== TRAVEL TIMES SCHEMA ===")
travel_times_df.printSchema()

# sample rows
print("\n=== SAMPLE ROWS ===")
travel_times_df.show(5, truncate=False)

# row count
print(f"\nTotal rows: {travel_times_df.count():,}")

# check speed restrictions schema
print("=== SPEED RESTRICTIONS SCHEMA ===")
restrictions_df.printSchema()

# sample rows
print("\n=== SAMPLE ROWS ===")
restrictions_df.show(5, truncate=False)

# row count
print(f"\nTotal rows: {restrictions_df.count():,}")

from pyspark.sql.functions import col, count, when

# function to check nulls
def check_nulls(df, name):
    print(f"=== {name} - NULL COUNTS ===")
    null_counts = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])
    null_counts.show(vertical=True)

# check each dataset
check_nulls(survey_df, "SURVEY")
check_nulls(ridership_df, "RIDERSHIP")
check_nulls(travel_times_df, "TRAVEL TIMES")
check_nulls(restrictions_df, "SPEED RESTRICTIONS")

# check unique values in key fields to understand joins

print("=== POTENTIAL JOIN KEYS ===\n")

# 1. Route/Line identification
print("RIDERSHIP - Unique Routes:")
ridership_df.select("route_id").distinct().orderBy("route_id").show()

print("TRAVEL TIMES - Unique Routes:")
travel_times_df.select("route_id").distinct().orderBy("route_id").show()

print("RESTRICTIONS - Unique Lines:")
restrictions_df.select("Line").distinct().orderBy("Line").show()


# 2. Station/Stop identification
print("\nRIDERSHIP - Sample Stations:")
ridership_df.select("parent_station", "stop_name").distinct().show(5)

print("TRAVEL TIMES - Sample Stations:")
travel_times_df.select("from_parent_station", "from_stop_name").distinct().show(5)

# 3. Time periods
print("\nRIDERSHIP - Time Periods:")
ridership_df.select("time_period_name").distinct().show()

print("TRAVEL TIMES - Date Range:")
travel_times_df.select(min("service_date"), max("service_date")).show()

print("RESTRICTIONS - Date Range:")
restrictions_df.select(min("Calendar_Date"), max("Calendar_Date")).show()

print("=== DATA EXPLORATION SUMMARY ===\n")

# dataset sizes
print("DATASET SIZES:")
print(f"  Survey: {survey_df.count():,} rows (aggregated percentages)")
print(f"  Ridership: {ridership_df.count():,} rows (stop-level counts)")
print(f"  Travel Times: {travel_times_df.count():,} rows (trip-level)")
print(f"  Restrictions: {restrictions_df.count():,} rows (daily restrictions)")

# join key summary
print("\n‚úÖ JOIN KEYS IDENTIFIED:")
print("  Route/Line: route_id (Ridership, Travel Times) ‚Üí Line (Restrictions)")
print("    - Need to map: 'Red' ‚Üí 'Red Line', 'Orange' ‚Üí 'Orange Line', etc.")
print("  Station: parent_station (Ridership) ‚Üî from_parent_station (Travel Times)")
print("  Time: service_date (Travel Times) ‚Üî Calendar_Date (Restrictions)")
print("  Period: time_period_name (Ridership) - needs mapping to Travel Times")

# date coverage
print("\nüìÖ DATE COVERAGE:")
print("  Travel Times: Full year 2024 (Jan 1 - Dec 31)")
print("  Restrictions: Jan 1 - Nov 5, 2024")
print("  Ridership: Fall 2024 only")

# check travel time distribution
print("\nüìä TRAVEL TIME STATISTICS:")
travel_times_df.select("travel_time_sec").describe().show()

# check ridership distribution
print("üìä RIDERSHIP STATISTICS:")
ridership_df.select("average_flow").describe().show()

# check restriction severity
print("üìä RESTRICTION SPEEDS:")
restrictions_df.groupBy("Restriction_Speed_MPH").count().orderBy("count", ascending=False).show()

import matplotlib.pyplot as plt
import seaborn as sns

# convert to pandas for plotting
travel_times_pd = travel_times_df.select("travel_time_sec", "route_id").toPandas()
ridership_pd = ridership_df.select("average_flow", "route_id", "time_period_name").toPandas()
restrictions_pd = restrictions_df.select("Restriction_Speed_MPH", "Line", "Restriction_Distance_Miles").toPandas()

# create figure with subplots
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. travel time distribution by route
sns.boxplot(data=travel_times_pd, x="route_id", y="travel_time_sec", ax=axes[0,0])
axes[0,0].set_title("Travel Time Distribution by Route")
axes[0,0].set_ylabel("Travel Time (seconds)")
axes[0,0].set_xlabel("Route")

# 2. ridership by time period
ridership_summary = ridership_pd.groupby("time_period_name")["average_flow"].sum().sort_values(ascending=False)
ridership_summary.plot(kind="bar", ax=axes[0,1], color="steelblue")
axes[0,1].set_title("Total Ridership by Time Period")
axes[0,1].set_ylabel("Total Flow")
axes[0,1].set_xlabel("Time Period")
axes[0,1].tick_params(axis='x', rotation=45)

# 3. speed restriction severity
restrictions_pd["speed"] = restrictions_pd["Restriction_Speed_MPH"].str.extract(r'(\d+)').astype(float)
sns.histplot(data=restrictions_pd, x="speed", bins=10, ax=axes[1,0], kde=True)
axes[1,0].set_title("Speed Restriction Distribution")
axes[1,0].set_xlabel("Restriction Speed (MPH)")
axes[1,0].set_ylabel("Count")

# 4. restrictions by line
restrictions_summary = restrictions_pd.groupby("Line").size().sort_values(ascending=False)
restrictions_summary.plot(kind="barh", ax=axes[1,1], color="coral")
axes[1,1].set_title("Speed Restrictions by Line")
axes[1,1].set_xlabel("Count")

plt.tight_layout()
plt.show()

print("‚úÖ Visualizations complete")

print("="*60)
print("DATA EXPLORATION COMPLETE - KEY FINDINGS")
print("="*60)

print("\nüìä DATASETS OVERVIEW:")
print("  ‚úì Survey: 200 aggregated responses (percentages by group)")
print("  ‚úì Ridership: 200 stop-level records (Fall 2024)")
print("  ‚úì Travel Times: 1,000 trip records (full year 2024)")
print("  ‚úì Restrictions: 200 daily restriction records")

print("\nüîë JOIN STRATEGY:")
print("  1. Route: 'Red'/'Orange'/'Blue' ‚Üí 'Red Line'/'Orange Line'/'Blue Line'")
print("  2. Station: parent_station fields match across datasets")
print("  3. Date: service_date ‚Üî Calendar_Date")
print("  4. Time Period: map time_period_name to hour ranges")

print("\nüìà KEY INSIGHTS:")
print("  ‚Ä¢ Red Line has highest travel time variability (outliers up to 5000s)")
print("  ‚Ä¢ OFF_PEAK has highest total ridership")
print("  ‚Ä¢ 25 MPH restrictions most common (107 instances)")
print("  ‚Ä¢ Red/Orange Lines have most restrictions")

print("\n‚ö†Ô∏è DATA QUALITY NOTES:")
print("  ‚Ä¢ Active restrictions have NULL cleared dates (expected)")
print("  ‚Ä¢ Sample data only - full analysis needs complete datasets")
print("  ‚Ä¢ Green Line in restrictions but not in ridership/travel_times samples")

print("\n‚úÖ NEXT STEPS (Week 2):")
print("  1. Define indicators:")
print("     - Travel time reliability (median, 90th percentile, volatility)")
print("     - Restriction impact (% miles restricted, avg speed)")
print("     - Ridership exposure weights")
print("  2. Normalize indicators (z-scores)")
print("  3. Set initial weights (equal or rule-based)")
print("  4. Compute RSS prototype for pilot lines")
print("  5. Validate against survey satisfaction")

print("\nüìÅ SAVE THIS NOTEBOOK AS: notebooks/01_data_exploration.ipynb")
print("="*60)

