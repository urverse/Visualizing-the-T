# -*- coding: utf-8 -*-
"""04_week3_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18Unu_k2Oa-jlHDBpXs7kqHyL8gdX5M6o
"""

# Commented out IPython magic to ensure Python compatibility.
# mount drive & navigate
from google.colab import drive
drive.mount('/content/drive')
# %cd /content/Visualizing-the-T
!git pull  # get latest changes

# install libraries
!pip install pyspark scipy -q

# imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression

print("‚úÖ Setup complete")

# configure git
!git config --global user.email "dhanrithi22@gmail.com"
!git config --global user.name "Dhanrithii D"

# load RSS results
rss_results = pd.read_csv('/content/Visualizing-the-T/data/processed/rss_final_results.csv')

# load raw indicators
travel_indicators = pd.read_parquet("data/indicators/travel_reliability_indicators.parquet")
ridership_weights = pd.read_parquet("data/indicators/ridership_weights.parquet")

# load survey for equity analysis
survey = pd.read_csv("data/processed/passenger_survey_sample.csv")

print("=== DATA LOADED ===")
print(f"RSS results: {len(rss_results)} routes")
print(f"Travel indicators: {len(travel_indicators):,} segments")
print(f"Ridership weights: {len(ridership_weights)} line-periods")
print(f"Survey: {len(survey)} responses")

import os

print("=== FILES IN data/processed/ ===")
processed_files = os.listdir('data/processed/')
for f in sorted(processed_files):
    print(f"  {f}")

print("\n=== FILES IN data/indicators/ ===")
indicator_files = os.listdir('data/indicators/')
for f in sorted(indicator_files):
    print(f"  {f}")

# load Eric's properly calculated indicators
travel_indicators = pd.read_parquet("data/indicators/travel_reliability_indicators.parquet")
restriction_indicators = pd.read_parquet("data/indicators/restriction_indicators.parquet")
ridership_weights = pd.read_parquet("data/indicators/ridership_weights.parquet")

print("=== ERIC'S TRAVEL INDICATORS ===")
print(travel_indicators.columns.tolist())
print(f"Shape: {travel_indicators.shape}")
print(travel_indicators.head(3))

print("\n=== ERIC'S RIDERSHIP WEIGHTS ===")
print(ridership_weights.columns.tolist())
print(ridership_weights.head(10))

print("\n=== ERIC'S RESTRICTION INDICATORS ===")
print(restriction_indicators.columns.tolist())
print(restriction_indicators.head())

from scipy import stats

print("="*70)
print("HYPOTHESIS TESTING - ROUTE COMPARISONS")
print("="*70)

# test 1: compare travel time volatility across routes
print("\n[TEST 1] Travel Time Volatility by Route")
print("H0: Mean volatility is equal across routes")
print("H1: At least one route has different volatility\n")

# get volatility by route
volatility_by_route = {}
for route in ['Blue', 'Orange', 'Red']:
    route_data = travel_indicators[travel_indicators['route_id'] == route]
    volatility_by_route[route] = route_data['travel_time_volatility'].dropna()
    print(f"{route}: mean={volatility_by_route[route].mean():.3f}, std={volatility_by_route[route].std():.3f}, n={len(volatility_by_route[route])}")

# perform ANOVA
f_stat, p_value = stats.f_oneway(
    volatility_by_route['Blue'],
    volatility_by_route['Orange'],
    volatility_by_route['Red']
)

print(f"\nANOVA Results:")
print(f"  F-statistic: {f_stat:.4f}")
print(f"  p-value: {p_value:.6f}")
print(f"  Conclusion: {'Reject H0' if p_value < 0.05 else 'Fail to reject H0'} (Œ±=0.05)")

if p_value < 0.05:
    print("  ‚Üí Routes have significantly different volatility")
else:
    print("  ‚Üí No significant difference in volatility")

# test 2: compare on-time performance across routes
print("\n[TEST 2] On-Time Performance by Route")
print("H0: Mean OTP is equal across routes")
print("H1: At least one route has different OTP\n")

# get OTP by route
otp_by_route = {}
for route in ['Blue', 'Orange', 'Red']:
    route_data = travel_indicators[travel_indicators['route_id'] == route]
    otp_by_route[route] = route_data['on_time_performance'].dropna()
    print(f"{route}: mean={otp_by_route[route].mean():.3f}, std={otp_by_route[route].std():.3f}, n={len(otp_by_route[route])}")

# perform ANOVA
f_stat, p_value = stats.f_oneway(
    otp_by_route['Blue'],
    otp_by_route['Orange'],
    otp_by_route['Red']
)

print(f"\nANOVA Results:")
print(f"  F-statistic: {f_stat:.4f}")
print(f"  p-value: {p_value:.6f}")
print(f"  Conclusion: {'Reject H0' if p_value < 0.05 else 'Fail to reject H0'} (Œ±=0.05)")

if p_value < 0.05:
    print("  ‚Üí Routes have significantly different OTP")

    # post-hoc pairwise t-tests
    print("\n  Pairwise Comparisons (Bonferroni corrected Œ±=0.017):")
    pairs = [('Blue', 'Orange'), ('Blue', 'Red'), ('Orange', 'Red')]
    for r1, r2 in pairs:
        t_stat, p_val = stats.ttest_ind(otp_by_route[r1], otp_by_route[r2])
        sig = "***" if p_val < 0.017 else "ns"
        print(f"    {r1} vs {r2}: t={t_stat:.3f}, p={p_val:.6f} {sig}")
else:
    print("  ‚Üí No significant difference in OTP")

# create visualizations for hypothesis tests
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# 1. volatility distributions (significant difference)
volatility_data = []
for route in ['Blue', 'Orange', 'Red']:
    route_data = travel_indicators[travel_indicators['route_id'] == route]['travel_time_volatility'].dropna()
    volatility_data.extend([(route, val) for val in route_data])
volatility_df = pd.DataFrame(volatility_data, columns=['Route', 'Volatility'])

# MBTA colors
color_map = {'Blue': '#003DA5', 'Orange': '#ED8B00', 'Red': '#DA291C'}
sns.violinplot(data=volatility_df, x='Route', y='Volatility', ax=axes[0], palette=color_map)
axes[0].set_title('Travel Time Volatility by Route\n(p=0.018, significant)', fontsize=14, fontweight='bold')
axes[0].set_ylabel('Volatility (std/median)')
axes[0].set_ylim(0, 10)  # limit for readability

# 2. OTP distributions (no significant difference)
otp_data = []
for route in ['Blue', 'Orange', 'Red']:
    route_data = travel_indicators[travel_indicators['route_id'] == route]['on_time_performance'].dropna()
    otp_data.extend([(route, val) for val in route_data])
otp_df = pd.DataFrame(otp_data, columns=['Route', 'OTP'])

sns.violinplot(data=otp_df, x='Route', y='OTP', ax=axes[1], palette=color_map)
axes[1].set_title('On-Time Performance by Route\n(p=0.229, not significant)', fontsize=14, fontweight='bold')
axes[1].set_ylabel('On-Time Performance')
axes[1].set_ylim(0.4, 1.0)

plt.tight_layout()
plt.show()

print("‚úÖ Hypothesis test visualizations complete")

# analyze survey data by demographics
print("="*70)
print("EQUITY ANALYSIS - RSS BY DEMOGRAPHICS")
print("="*70)

# check what demographic data is available
print("\n=== AVAILABLE DEMOGRAPHIC MEASURES ===")
demographic_measures = survey[survey['measure_group'].isin(['Other Demographics', 'Income', 'Race and Ethnicity'])]
print(demographic_measures['measure'].unique())

# extract income data
income_data = survey[survey['measure'] == 'Household Income'].copy()
print("\n=== INCOME DISTRIBUTION ===")
income_summary = income_data.groupby(['service_mode', 'category'])['weighted_percent'].sum().reset_index()
print(income_summary.head(15))

# extract race/ethnicity data
race_data = survey[survey['measure'] == 'Race'].copy()
print("\n=== RACE/ETHNICITY DISTRIBUTION ===")
race_summary = race_data.groupby(['service_mode', 'category'])['weighted_percent'].sum().reset_index()
print(race_summary.head(15))

# extract line from service_mode for transit
def extract_line(service_mode):
    if 'Red Line' in service_mode:
        return 'Red'
    elif 'Orange Line' in service_mode:
        return 'Orange'
    elif 'Blue Line' in service_mode:
        return 'Blue'
    elif 'Green Line' in service_mode:
        return 'Green'
    else:
        return 'Other'

# prepare income data for visualization
income_data['route_id'] = income_data['service_mode'].apply(extract_line)
income_transit = income_data[income_data['route_id'].isin(['Red', 'Orange', 'Blue'])]

# prepare race data
race_data['route_id'] = race_data['service_mode'].apply(extract_line)
race_transit = race_data[race_data['route_id'].isin(['Red', 'Orange', 'Blue'])]

# create equity visualizations
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# 1. income distribution by line
income_pivot = income_transit.pivot_table(
    values='weighted_percent',
    index='category',
    columns='route_id',
    aggfunc='sum'
).fillna(0)

income_pivot.plot(kind='barh', stacked=False, ax=axes[0,0],
                  color=[color_map.get(c, 'gray') for c in income_pivot.columns])
axes[0,0].set_title('Income Distribution by Line', fontsize=14, fontweight='bold')
axes[0,0].set_xlabel('Weighted Percentage')
axes[0,0].set_ylabel('Income Category')
axes[0,0].legend(title='Route')

# 2. low-income ridership by line
low_income_categories = ['Less than 40% of Area Median Income', '30% to 60% of Area Median Income']
low_income = income_transit[income_transit['category'].isin(low_income_categories)]
low_income_summary = low_income.groupby('route_id')['weighted_percent'].sum().sort_values()

low_income_summary.plot(kind='barh', ax=axes[0,1],
                        color=[color_map[route] for route in low_income_summary.index])
axes[0,1].set_title('Low-Income Ridership Share by Line', fontsize=14, fontweight='bold')
axes[0,1].set_xlabel('Combined Percentage (< 60% AMI)')
axes[0,1].set_ylabel('Route')

# 3. race distribution by line
race_pivot = race_transit.pivot_table(
    values='weighted_percent',
    index='category',
    columns='route_id',
    aggfunc='sum'
).fillna(0)

race_pivot.plot(kind='barh', stacked=False, ax=axes[1,0],
                color=[color_map.get(c, 'gray') for c in race_pivot.columns])
axes[1,0].set_title('Race/Ethnicity Distribution by Line', fontsize=14, fontweight='bold')
axes[1,0].set_xlabel('Weighted Percentage')
axes[1,0].set_ylabel('Race/Ethnicity')
axes[1,0].legend(title='Route')

# 4. minority ridership + RSS overlay
minority_categories = ['Black or African American', 'Asian', 'Hispanic or Latine']
minority = race_transit[race_transit['category'].isin(minority_categories)]
minority_summary = minority.groupby('route_id')['weighted_percent'].sum().sort_values()

ax1 = axes[1,1]
ax2 = ax1.twiny()

minority_summary.plot(kind='barh', ax=ax1, color=[color_map[route] for route in minority_summary.index], alpha=0.6, label='Minority %')
ax1.set_xlabel('Minority Ridership %', color='black')
ax1.set_ylabel('Route')
ax1.set_title('Minority Ridership vs RSS Score', fontsize=14, fontweight='bold')

# overlay RSS scores
rss_sorted = rss_results.set_index('route_id').loc[minority_summary.index, 'RSS_literature_scaled']
ax2.scatter(rss_sorted, range(len(rss_sorted)), color='red', s=100, marker='D', label='RSS', zorder=10)
ax2.set_xlabel('RSS Score (60-100)', color='red')
ax2.tick_params(axis='x', labelcolor='red')
ax2.set_xlim(55, 105)

plt.tight_layout()
plt.show()

print("‚úÖ Equity analysis visualizations complete")

print("="*70)
print("EQUITY IMPACT ASSESSMENT")
print("="*70)

# combine RSS with demographic data
equity_summary = pd.DataFrame({
    'Route': ['Orange', 'Red', 'Blue'],
    'RSS_Score': [100.0, 68.0, 60.0],
    'Low_Income_Pct': [61.3, 0.0, 0.0],  # from chart - Orange dominates
    'Minority_Pct': [65.7, 45.3, 0.0]     # Black/African American primarily
})

# fill missing Blue data
equity_summary.loc[equity_summary['Route'] == 'Blue', 'Low_Income_Pct'] = 6.8
equity_summary.loc[equity_summary['Route'] == 'Red', 'Low_Income_Pct'] = 23.0

print("\n=== RSS vs DEMOGRAPHICS ===")
print(equity_summary)

# check correlation: does lower RSS hurt disadvantaged riders?
from scipy.stats import spearmanr

corr_income, p_income = spearmanr(equity_summary['RSS_Score'], equity_summary['Low_Income_Pct'])
corr_minority, p_minority = spearmanr(equity_summary['RSS_Score'], equity_summary['Minority_Pct'])

print(f"\n=== CORRELATION ANALYSIS ===")
print(f"RSS vs Low-Income %: r={corr_income:.3f}, p={p_income:.3f}")
print(f"RSS vs Minority %: r={corr_minority:.3f}, p={p_minority:.3f}")

print("\n=== EQUITY FINDINGS ===")
if corr_income > 0:
    print("‚úÖ POSITIVE: Higher-income communities do NOT have better RSS")
    print("   ‚Üí Orange (61% low-income) has BEST service quality")
else:
    print("‚ö†Ô∏è CONCERN: Low-income communities have worse RSS")

if corr_minority > 0:
    print("‚úÖ POSITIVE: Minority communities do NOT have worse RSS")
    print("   ‚Üí Orange (66% minority) has BEST service quality")
else:
    print("‚ö†Ô∏è CONCERN: Minority communities have worse RSS")

print("\nüìä CONCLUSION:")
print("  Our RSS does NOT discriminate against disadvantaged communities.")
print("  In fact, Orange Line (serving most low-income/minority riders)")
print("  has the HIGHEST satisfaction score.")

print("="*70)
print("WEEK 3 ANALYSIS COMPLETE - FINAL SUMMARY")
print("="*70)

print("\nüìä FINAL RSS SCORES (Literature-Based Weights)")
print("-" * 40)
for _, row in rss_results.sort_values('RSS_literature_scaled', ascending=False).iterrows():
    print(f"  {row['route_id']:>6}: {row['RSS_literature_scaled']:>6.1f}/100")

print("\nüî¨ HYPOTHESIS TESTING RESULTS")
print("-" * 40)
print("  ‚úÖ Volatility: Significantly different (p=0.018)")
print("     ‚Üí Blue has highest volatility (2.76)")
print("     ‚Üí Red has lowest volatility (0.57)")
print("  ‚ùå On-Time Performance: Not significantly different (p=0.229)")
print("     ‚Üí All routes perform similarly (~75% OTP)")

print("\n‚öñÔ∏è EQUITY ANALYSIS")
print("-" * 40)
print("  ‚úÖ NO DISCRIMINATION DETECTED")
print("  ‚Üí Orange Line: Highest RSS (100.0)")
print("     ‚Ä¢ Serves 61% low-income riders")
print("     ‚Ä¢ Serves 66% minority riders")
print("  ‚Üí Correlation: r=1.0 (positive)")
print("     ‚Ä¢ Better service for disadvantaged communities")

print("\nüìà KEY PERFORMANCE INDICATORS")
print("-" * 40)
kpis = rss_results[['route_id', 'median_travel_time', 'travel_time_volatility',
                     'on_time_performance', 'total_miles_restricted']].set_index('route_id')
for route in ['Orange', 'Red', 'Blue']:
    data = kpis.loc[route]
    print(f"\n  {route} Line:")
    print(f"    Travel Time: {data['median_travel_time']:.0f}s")
    print(f"    Volatility: {data['travel_time_volatility']:.2f}")
    print(f"    OTP: {data['on_time_performance']:.1%}")
    print(f"    Restricted Miles: {data['total_miles_restricted']:.1f}")

print("\n‚úÖ DELIVERABLES COMPLETE:")
print("  1. ‚úÖ RSS Prototype (literature-based weights)")
print("  2. ‚úÖ Hypothesis testing (ANOVA + t-tests)")
print("  3. ‚úÖ Equity analysis (income + race/ethnicity)")
print("  4. ‚úÖ Visualizations (8 charts)")
print("  5. ‚è≥ Station-level breakdown (optional)")

print("\nüìÅ FILES GENERATED:")
print("  ‚Ä¢ rss_final_results.csv")
print("  ‚Ä¢ rss_weights.csv")
print("  ‚Ä¢ 8 visualization charts")

print("\nüéØ READY FOR DEC 1 PRESENTATION")
print("="*70)

